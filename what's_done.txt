1) За допомогoю groupby i decode_rle та на основі файлу csv створив папку masks де лежать всі маски.
Код як перетворював рядки з RLE на зображення зберіг у RLE_decoding.py
2) Створив модель вирішив перевірити чи при меншій кількості фільтрів і більш глибокій моделі вона буде працювати краще
на даних ніж класична U-Net, за допомогою Google Cloud вчу її. Код завантаження даних, побудови і навчання моделі зберіг
в model.py.
3) модель навчав на Google Cloud використовував просто python model.py і screen щоб все працювало в фоновому режимі без мене
4) нічого не вийшло через декілька помилок(точність була ххх на 10 в мінус сьомій степені), виправив модель і помилки(чомусь
не працювала нормалізація вхідних зображень, також датасет був неповний, додав BatchNormalzition на кожний етап і
замінив слої при зведенні на SeparableConv2D в результаті 1м параметрів замість двох)
5) запустив нову, проблема була з масками, на другій епосі отримав loss 0.033 мабуть треба брати іншу функцію втрати а також
навчати модель тільки на даних де є кораблі і навчити ше другу модель визначати чи є кораблі на картинці
6) змінив RLE-decoding тепер він створює файл тільки якщо є корабель, вийшло 46тис картинок/масок поміняв метрики для
визначення точності і loss також замінив тип даних для масок і розібрався з tf_image.convert_image_dtype() запустив навчання моделі
Треба тепер створювать модель яка буде визначати чи є на картинці корабель чи немає
7) навчив сегментаційну модель вийшло по val_Dice_coef 0.75 після 40 епох, треба буде шось придумать і якось довчить бо
хотілось би краще
8) створив модель детекції кораблів, прийшлось створювать новий датасет, код створення в файлі Dataset_for_classification.py,
в файлі Classification_model.py завантаження даних створення і навчання моделі детекції кораблів
9) трошки прорахувався з розмірностями в моделі детекції, в результаті отримав модель з 112 мільйонами параметрів що не хотіла
навчатись зменшив, кількість фільтрів і Dense layer і вроді все стало ок.
10) знайшов інший спосіб обрахунку combined dice/cross-entropy loss, треба спробувати довчити сегментаційну модель,
плюс використовувати всі 62 тис картинок на навчання/валідацію плюс переробити dice_p_bce
https://github.com/shruti-jadon/Semantic-Segmentation-Loss-Functions/tree/master/loss_functions.py
11) в файлі main.py написав код для реалізації всього процесу(завантаження картинки->ship detection->segmentation якщо знайдений
корабель) результати більш-менш ок але треба краще
12) вирішив перенавчити модель буду використовувати augmented дані, нову loss function і вчить на всьому датасеті, код реалізації
аугментації зберіг в data_augmentation.py
13) чогось після донавччання модель перестала працювати корректно, мабуть overfitting
14) не overfitting, при аугментації даних допустив помилку і завантажив input images і в картинки і в маски,
виправив код, перестворив датасет, навчив модель з новою loss function модель стала краще, навіть без ship detection добре працює.





'''
gcloud compute scp instance-template-gpu-20240221-222820:~/working_dir/ship_detection_model.keras /Users/maxim/PycharmProjects/Ship_Detection_Challenge/
'''


