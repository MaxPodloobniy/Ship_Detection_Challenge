1) За допомогoю groupby i decode_rle та на основі файлу csv створив папку masks де лежать всі маски.
Код як перетворював рядки з RLE на зображення зберіг у RLE_decoding.py
2) Створив модель вирішив перевірити чи при меншій кількості фільтрів і більш глибокій моделі вона буде працювати краще
на даних ніж класична U-Net, за допомогою Google Cloud вчу її. Код завантаження даних, побудови і навчання моделі зберіг
в model.py.
3) модель навчав на Google Cloud використовував просто python model.py і screen щоб все працювало в фоновому режимі без мене
4) нічого не вийшло через декілька помилок(точність була ххх на 10 в мінус сьомій степені), виправив модель і помилки(чомусь
не працювала нормалізація вхідних зображень, також датасет був неповний, додав BatchNormalzition на кожний етап і
замінив слої при зведенні на SeparableConv2D в результаті 1м параметрів замість двох також додав регулятор швидкості навчання)
5) запустив нову, проблема була з масками, на другій епосі отримав loss 0.033 мабуть треба брати іншу функцію втрати а також
навчати модель тільки на даних де є кораблі і навчити ше другу модель визначати чи є кораблі на картинці
6) змінив RLE-decoding тепер він створює файл тільки якщо є корабель, вийшло 46тис картинок/масок поміняв метрики для
визначення точності і loss також замінив тип даних для масок і розібрався з tf_image.convert_image_dtype() запустив навчання моделі
Треба тепер створювать модель яка буде визначати чи є на картинці корабель чи немає
7) навчив сегментаційну модель вийшло по val_Dice_coef 0.75 після 40 епох треба буде шось придумать і якось довчить бо
хотілось би краще
8) створив модель детекції кораблів, прийшлось створювать новий датасет, код створення в файлі Dataset_for_classification.py,
в файлі Classification_model.py завантаження даних створення і навчання моделі детекції кораблів